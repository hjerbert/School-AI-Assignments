{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Koneoppiminen: Osa 3: Naiivi Bayes-luokittelija"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "student_info"
    ]
   },
   "outputs": [],
   "source": [
    "# Kirjoita tähän tietosi!\n",
    "student_name = 'Ville Karjalainen'\n",
    "student_id = 'AA5075'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tehtävä 1\n",
    "### Aihe: Artificial Characters Data Set\n",
    "\n",
    "4 pistettä\n",
    "\n",
    "1. Tutustu *Wine Data Set* -aineistoon osoitteessa https://archive.ics.uci.edu/ml/datasets/Wine .\n",
    "\n",
    "2. Lataa aineisto ja aseta sarakkeiden nimet. \n",
    "\n",
    "3. Jaa aineisto koulutus- ja testausaineistoon käyttäen `scikit-learn`-kirjaston [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)-funktiota.  \n",
    "\n",
    "4. Normalisoi sarakkeet välille 0...1 `scikit-learn`-kirjaston `preprocessing`-moduulin [minmax_scale](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.minmax_scale.html#sklearn.preprocessing.minmax_scale)-funktiolla.\n",
    "\n",
    "- Tallenna koulutusaineisto ja sen luokkamuuttuja muuttujiin `X_train`, `y_train`,\n",
    "- ja toisaalta testausaineiston `X_test`, `y_test`. \n",
    "\n",
    "Aseta testausjoukon kooksi 33% ja satunnaisuuden siemeneksi `1900`.\n",
    "\n",
    "Vinkki: älä skaalaa luokkamuuttujaa. \n",
    "\n",
    "Vinkki: muista että luokkamuuttuja ei mene `X`-muuttujiin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kirjoita toteutuksesi tähän soluun. \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "# aseta sarakkeiden nimet ja määritä datan url\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data'\n",
    "\n",
    "columns = [\n",
    "'Class',\n",
    "'Alcohol',\n",
    "'Malic acid',\n",
    "'Ash',\n",
    "'Alcalinity of ash',\n",
    "'Magnesium',\n",
    "'Total phenols',\n",
    "'Flavanoids',\n",
    "'Nonflavanoid phenols',\n",
    "'Proanthocyanins',\n",
    "'Color intensity',\n",
    "'Hue',\n",
    "'OD280/OD315 of diluted wines',\n",
    "'Proline'\n",
    "]\n",
    "\n",
    "# Lataa aineisto muuttujaan \n",
    "data = pd.read_csv(url, names=columns)\n",
    "\n",
    "\n",
    "# Jaa aineisto koulutus- ja testausaineistoon käyttäen scikit-learn-kirjaston train_test_split-funktiota.\n",
    "X = data.drop('Class', 1)\n",
    "y = data['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    # Aseta testausjoukon kooksi 33% ja satunnaisuuden siemeneksi 1900\n",
    "                                                    test_size= 0.33, random_state= 1900)\n",
    "\n",
    "\n",
    "\n",
    "# Normalisoi sarakkeet välille 0...1 scikit-learn-kirjaston preprocessing-moduulin minmax_scale-funktiolla.\n",
    "scaler = MinMaxScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X_train.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": [
     "answer_3_1"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train columns: Index(['Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash', 'Magnesium',\n",
      "       'Total phenols', 'Flavanoids', 'Nonflavanoid phenols',\n",
      "       'Proanthocyanins', 'Color intensity', 'Hue',\n",
      "       'OD280/OD315 of diluted wines', 'Proline'],\n",
      "      dtype='object')\n",
      "X_train:       Alcohol  Malic acid       Ash  Alcalinity of ash  Magnesium  \\\n",
      "0    0.288690    0.531621  0.196078           0.414894   0.246377   \n",
      "1    0.848214    0.849802  0.346405           0.468085   0.144928   \n",
      "2    0.550595    0.444664  0.457516           0.468085   0.492754   \n",
      "3    0.157738    0.258893  1.000000           0.920213   0.710145   \n",
      "4    0.636905    0.365613  0.437908           0.468085   0.724638   \n",
      "..        ...         ...       ...                ...        ...   \n",
      "114  0.547619    0.764822  0.509804           0.547872   0.231884   \n",
      "115  0.854167    0.185771  0.274510           0.255319   0.449275   \n",
      "116  0.479167    0.122530  0.209150           0.297872   0.434783   \n",
      "117  0.250000    0.705534  0.450980           0.521277   0.173913   \n",
      "118  0.773810    0.211462  0.653595           0.319149   0.608696   \n",
      "\n",
      "     Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
      "0         0.351724    0.274262              0.452830         0.458861   \n",
      "1         0.000000    0.000000              0.509434         0.082278   \n",
      "2         0.110345    0.185654              0.207547         0.129747   \n",
      "3         0.758621    1.000000              0.641509         0.458861   \n",
      "4         0.231034    0.071730              0.754717         0.329114   \n",
      "..             ...         ...                   ...              ...   \n",
      "114       0.248276    0.065401              0.641509         0.139241   \n",
      "115       0.731034    0.643460              0.150943         0.544304   \n",
      "116       0.358621    0.225738              0.754717         0.063291   \n",
      "117       0.648276    0.567511              0.150943         0.787975   \n",
      "118       0.644828    0.542194              0.320755         0.329114   \n",
      "\n",
      "     Color intensity       Hue  OD280/OD315 of diluted wines   Proline  \n",
      "0           0.000000  0.365854                      0.652015  0.231205  \n",
      "1           0.345750  0.081301                      0.021978  0.110752  \n",
      "2           0.393505  0.211382                      0.054945  0.203719  \n",
      "3           0.450812  0.365854                      0.886447  0.151172  \n",
      "4           0.765998  0.097561                      0.128205  0.454325  \n",
      "..               ...       ...                           ...       ...  \n",
      "114         0.608405  0.048780                      0.216117  0.280517  \n",
      "115         0.460363  0.349593                      0.754579  0.571544  \n",
      "116         0.426934  0.406504                      0.117216  0.139046  \n",
      "117         0.145177  0.219512                      0.868132  0.082458  \n",
      "118         0.574976  0.650407                      0.589744  0.834276  \n",
      "\n",
      "[119 rows x 13 columns]\n",
      "X_test:      Alcohol  Malic acid       Ash  Alcalinity of ash  Magnesium  \\\n",
      "0   0.440476    0.098814  0.359477           0.335106   0.217391   \n",
      "1   0.785714    0.100791  0.143791           0.361702   0.347826   \n",
      "2   0.657738    0.640316  0.385621           0.335106   0.478261   \n",
      "3   0.497024    0.618577  0.457516           0.627660   0.449275   \n",
      "4   0.351190    0.088933  0.032680           0.297872   1.173913   \n",
      "5   0.348214    0.452569  0.405229           0.414894   0.376812   \n",
      "6   1.107143    0.195652  0.450980           0.010638   0.304348   \n",
      "7   0.812500    0.156126  0.653595           0.441489   0.898551   \n",
      "8   1.130952    0.177866  0.307190           0.148936   0.391304   \n",
      "9   0.235119    0.144269  0.189542           0.510638   0.231884   \n",
      "10  0.398810    0.039526 -0.222222          -0.031915   0.260870   \n",
      "11  0.300595    0.703557  0.444444           0.574468   0.144928   \n",
      "12  0.815476    0.229249  0.640523           0.313830   0.652174   \n",
      "13  0.413690    0.729249  0.673203           0.813830   0.463768   \n",
      "14  0.791667    0.498024  0.549020           0.468085   0.536232   \n",
      "15  0.446429    0.942688  0.614379           0.734043   0.376812   \n",
      "16  0.946429    0.652174  0.483660           0.409574   0.594203   \n",
      "17  0.940476    0.167984  0.509804           0.281915   0.550725   \n",
      "18  0.803571    0.150198  0.653595           0.601064   0.449275   \n",
      "19  0.705357    0.626482  0.509804           0.627660   0.463768   \n",
      "20  0.574405    0.535573  0.424837           0.388298   0.521739   \n",
      "21  0.922619    0.664032  0.679739           0.707447   0.376812   \n",
      "22  0.901786    0.175889  0.379085           0.255319   0.811594   \n",
      "23  0.532738    0.519763  0.392157           0.441489   0.260870   \n",
      "24  0.389881    0.337945  0.496732           0.521277   0.405797   \n",
      "25  0.732143    0.563241  0.320261           0.441489   0.260870   \n",
      "26  0.217262    0.383399  0.797386           0.468085   0.478261   \n",
      "27  0.738095    0.209486  0.620915           0.414894   0.579710   \n",
      "28  0.866071    0.195652  0.372549           0.329787   0.550725   \n",
      "29  0.672619    0.243083  0.640523           0.297872   0.463768   \n",
      "30  0.428571    0.154150  0.326797           0.414894   1.333333   \n",
      "31  0.595238    0.031621  0.006536           0.255319   0.231884   \n",
      "32  0.797619    0.970356  0.490196           0.494681   0.362319   \n",
      "33  0.601190    0.258893  0.993464           0.734043   0.782609   \n",
      "34  0.919643    0.146245  0.405229           0.297872   0.362319   \n",
      "35  0.416667    0.156126  0.385621           0.547872   0.231884   \n",
      "36  0.669643    0.177866  0.745098           0.228723   0.579710   \n",
      "37  0.386905    0.071146  0.379085           0.255319   0.449275   \n",
      "38  0.901786    0.278656  0.594771           0.340426   0.739130   \n",
      "39  0.601190    0.203557  0.261438           0.308511   0.536232   \n",
      "40  0.241071    0.424901  0.346405           0.361702   0.608696   \n",
      "41  0.497024    0.555336  0.431373           0.547872   0.521739   \n",
      "42  0.788690    0.215415  0.431373           0.319149   0.492754   \n",
      "43  0.997024    0.563241  0.379085           0.255319   0.463768   \n",
      "44  0.985119    0.185771  0.653595           0.734043   0.405797   \n",
      "45  0.413690    0.171937  0.320261           0.601064   0.550725   \n",
      "46  0.889881    0.185771  0.333333           0.255319   0.376812   \n",
      "47  0.607143    0.150198  0.261438           0.228723   0.405797   \n",
      "48  0.619048    0.229249  0.686275           0.760638   0.666667   \n",
      "49  0.842262    0.152174  0.633987           0.734043   0.231884   \n",
      "50  0.752976    0.195652  0.496732           0.494681   0.666667   \n",
      "51  0.541667    0.500000  0.575163           0.574468   0.521739   \n",
      "52  0.375000    0.171937  0.333333           0.489362   0.478261   \n",
      "53  0.997024    0.223320  0.444444           0.042553   0.463768   \n",
      "54  0.693452    0.359684  0.424837           0.468085   0.275362   \n",
      "55  0.994048    0.239130  0.522876           0.297872   0.623188   \n",
      "56  0.544643    0.120553  0.405229           0.361702   0.753623   \n",
      "57  0.702381    0.203557  0.601307           0.260638   0.333333   \n",
      "58  0.517857    0.531621  0.183007           0.255319   0.144928   \n",
      "\n",
      "    Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
      "0        0.351724    0.050633              0.886792         0.262658   \n",
      "1        0.386207    0.305907              0.358491         0.098101   \n",
      "2        0.572414    0.483122              0.358491         0.392405   \n",
      "3        0.637931    0.466245              0.566038         0.484177   \n",
      "4        0.300000    0.198312              0.018868         0.658228   \n",
      "5        0.093103    0.031646              0.509434         0.098101   \n",
      "6        0.731034    0.706751              0.566038         0.756329   \n",
      "7        0.679310    0.506329              0.698113         0.294304   \n",
      "8        0.627586    0.556962              0.301887         0.493671   \n",
      "9        0.344828    0.265823              0.320755         0.351266   \n",
      "10       0.344828    0.048523              0.283019         0.000000   \n",
      "11       0.386207    0.297468              0.547170         0.294304   \n",
      "12       0.696552    0.516878              0.490566         0.398734   \n",
      "13       0.420690    0.377637              0.566038         0.408228   \n",
      "14       0.293103    0.046414              0.698113         0.120253   \n",
      "15       0.279310    0.054852              0.943396         0.215190   \n",
      "16       0.644828    0.487342              0.320755         0.262658   \n",
      "17       0.800000    0.757384              0.358491         0.455696   \n",
      "18       0.696552    0.613924              0.301887         0.620253   \n",
      "19       0.282759    0.086498              0.566038         0.313291   \n",
      "20       0.141379    0.075949              0.509434         0.164557   \n",
      "21       0.368966    0.088608              0.811321         0.294304   \n",
      "22       0.696552    0.597046              0.207547         0.531646   \n",
      "23       0.172414    0.067511              0.509434         0.174051   \n",
      "24       0.544828    0.373418              0.396226         0.281646   \n",
      "25       0.220690    0.029536              0.849057         0.145570   \n",
      "26       0.265517    0.356540              0.886792         0.199367   \n",
      "27       0.472414    0.462025              0.301887         0.354430   \n",
      "28       0.655172    0.675105              0.358491         0.525316   \n",
      "29       0.696552    0.609705              0.339623         0.392405   \n",
      "30       0.524138    0.407173              0.358491         0.905063   \n",
      "31       0.334483    0.356540              0.207547         0.329114   \n",
      "32       0.241379    0.056962              0.735849         0.202532   \n",
      "33       0.568966    0.493671              0.641509         0.474684   \n",
      "34       0.420690    0.440928              0.245283         0.363924   \n",
      "35       0.606897    0.592827              0.490566         0.427215   \n",
      "36       0.558621    0.493671              0.396226         0.297468   \n",
      "37       0.368966    0.158228              0.943396        -0.003165   \n",
      "38       0.558621    0.457806              0.339623         0.262658   \n",
      "39       0.696552    0.561181              0.283019         0.509494   \n",
      "40       0.255172    0.206751              0.566038         0.167722   \n",
      "41       0.248276    0.181435              0.075472         0.132911   \n",
      "42       0.496552    0.495781              0.547170         0.490506   \n",
      "43       0.782759    0.597046              0.264151         0.560127   \n",
      "44       0.627586    0.204641              0.754717         0.721519   \n",
      "45       0.351724    0.369198              0.396226         0.376582   \n",
      "46       0.575862    0.419831              0.245283         0.493671   \n",
      "47       0.489655    0.485232              0.283019         0.300633   \n",
      "48       0.420690    0.198312              0.245283         0.360759   \n",
      "49       0.679310    0.531646              0.150943         0.458861   \n",
      "50       0.682759    0.514768              0.132075         0.642405   \n",
      "51       0.231034    0.054852              0.886792         0.170886   \n",
      "52       0.041379    0.143460              0.452830         0.329114   \n",
      "53       0.800000    0.696203              0.301887         0.803797   \n",
      "54       0.144828    0.033755              0.452830         0.069620   \n",
      "55       0.989655    0.664557              0.207547         0.556962   \n",
      "56       0.182759    0.191983              0.150943         0.164557   \n",
      "57       0.644828    0.548523              0.396226         0.325949   \n",
      "58       0.224138    0.191983              0.566038         0.129747   \n",
      "\n",
      "    Color intensity       Hue  OD280/OD315 of diluted wines   Proline  \n",
      "0          0.398281  0.219512                      0.087912  0.300728  \n",
      "1          0.240688  0.609756                      0.435897  0.284559  \n",
      "2          0.294174  0.276423                      0.633700  0.324980  \n",
      "3          0.123209  0.577236                      0.681319  0.149555  \n",
      "4          0.149952  0.650407                      0.659341  0.355699  \n",
      "5          0.403056  0.146341                      0.205128  0.187551  \n",
      "6          0.393505  0.626016                      0.534799  0.704931  \n",
      "7          0.393505  0.626016                      0.633700  0.773646  \n",
      "8          0.374403  0.487805                      0.578755  0.620049  \n",
      "9          0.063992  0.382114                      0.754579  0.175424  \n",
      "10         0.063992  0.463415                      0.201465  0.195635  \n",
      "11         0.126074  0.252033                      0.476190  0.244139  \n",
      "12         0.479465  0.528455                      0.608059  0.886823  \n",
      "13         0.076409  0.357724                      0.677656  0.070331  \n",
      "14         0.439351  0.390244                      0.201465  0.324980  \n",
      "15         0.355301  0.276423                      0.153846  0.191593  \n",
      "16         0.378223  0.317073                      0.754579  0.648343  \n",
      "17         0.708691  0.609756                      0.567766  1.133387  \n",
      "18         0.422159  0.577236                      0.527473  0.814066  \n",
      "19         0.574976  0.178862                      0.106227  0.381568  \n",
      "20         0.382044  0.162602                      0.175824  0.320938  \n",
      "21         0.756447  0.105691                      0.120879  0.227971  \n",
      "22         0.417383  0.495935                      0.893773  0.405821  \n",
      "23         0.857689  0.195122                      0.175824  0.329022  \n",
      "24         0.145177  0.260163                      0.772894  0.129345  \n",
      "25         0.422159  0.268293                      0.201465  0.244139  \n",
      "26         0.240688  0.609756                      0.450549  0.265966  \n",
      "27         0.278892  0.504065                      0.586081  0.660469  \n",
      "28         0.727794  0.520325                      0.670330  0.793856  \n",
      "29         0.450812  0.479675                      0.575092  0.801940  \n",
      "30         0.126074  0.552846                      0.498168  0.532741  \n",
      "31         0.317096  0.577236                      0.443223  0.092158  \n",
      "32         0.613181  0.130081                      0.172161  0.373484  \n",
      "33         0.219675  0.528455                      0.706960  0.446241  \n",
      "34         0.355301  0.560976                      0.567766  0.810024  \n",
      "35         0.254059  0.170732                      0.575092  0.059822  \n",
      "36         0.317096  0.495935                      0.553114  0.486661  \n",
      "37         0.190067  0.626016                      0.146520  0.324980  \n",
      "38         0.360076  0.471545                      0.846154  0.822150  \n",
      "39         0.359121  0.325203                      0.761905  0.490703  \n",
      "40         0.130850  0.390244                      0.457875  0.179466  \n",
      "41         0.355301  0.243902                      0.007326  0.260307  \n",
      "42         0.244508  0.609756                      0.586081  0.575586  \n",
      "43         0.345750  0.455285                      0.794872  0.636217  \n",
      "44         1.119389  0.073171                      0.252747  0.308812  \n",
      "45         0.074499  0.471545                      0.619048  0.054163  \n",
      "46         0.326648  0.455285                      0.849817  0.611964  \n",
      "47         0.231137  0.569106                      0.520147  0.599838  \n",
      "48         0.555874  0.105691                      0.021978  0.118836  \n",
      "49         0.200573  0.715447                      0.692308  0.106710  \n",
      "50         0.474690  0.406504                      0.644689  0.680679  \n",
      "51         0.410697  0.317073                      0.307692  0.236055  \n",
      "52         0.169054  0.346341                      0.201465  0.478577  \n",
      "53         0.594078  0.585366                      0.633700  1.025869  \n",
      "54         0.412607  0.178862                      0.439560  0.405821  \n",
      "55         0.622732  0.308943                      0.798535  0.971706  \n",
      "56         0.269341  0.227642                      0.007326  0.284559  \n",
      "57         0.336199  0.357724                      0.714286  0.741310  \n",
      "58         0.202483  0.178862                      0.311355  0.075990  \n"
     ]
    }
   ],
   "source": [
    "# Tehtävän vastaukset. Huom! Älä muokkaa tätä solua, vaan aja se, kun olet suorittanut tehtävän. \n",
    "# Tallenna vastauksesi X_train- X_test-muuttujiin.\n",
    "print(f'X_train columns: {X_train.columns}')\n",
    "print(f'X_train: {X_train}')\n",
    "print(f'X_test: {X_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tehtävä 2\n",
    "### Aihe: Gaussian Naive Bayes\n",
    "\n",
    "2 pistettä\n",
    "\n",
    "Käytä `scikit-learn`-kirjastosta löytyvää *Gaussian Naive Bayes* -menetelmää aineiston luokittelemiseksi.\n",
    "\n",
    "Ennnusta testiaineiston luokka. Tallenna ennusteet `y_pred`-muuttujaan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kirjoita toteutuksesi tähän soluun.\n",
    "\n",
    "# tuodaan tarvittavat kirjastot\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "# tehdään malli\n",
    "model = GaussianNB()\n",
    "\n",
    "\n",
    "# koulutetaan malli\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# tallennetaan y_pred -nimiseen muuttujaan koneoppimisen tuottamat luokittelut eri viineille\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "answer_3_2"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    }
   ],
   "source": [
    "# Tehtävän vastaukset. Huom! Älä muokkaa tätä solua, vaan aja se, kun olet suorittanut tehtävän. \n",
    "# Tallenna ennusteen tulokset y_pred-muuttujaan.\n",
    "print(f'{len(y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tehtävä 3\n",
    "### Aihe: Tarkkuuden mittaaminen\n",
    "\n",
    "4 pistettä\n",
    "\n",
    "Hyödynnä `scikit-learn`-kirjaston `metrics`-moduulin funktioita ja laske luokittelutuloksesi **tarkkuus** sekä **sekaannusmatriisi**. Tallenna tarkkuus muuttujaan `acc` ja sekaannusmatriisi muuttujaan `cm`. \n",
    "\n",
    "Vinkki: onnistumista voit mitata ainoastaa testiaineiston osalta!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kirjoita toteutuksesi tähän soluun.\n",
    "from sklearn import metrics\n",
    "\n",
    "# tallennetaan muuttujiin tarkkuus ja sekannuusmatriisi. Eli verrataan testiaineiston tuloksia ennustettuihin lukuihin (y_pred)\n",
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "answer_3_3"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9830508474576272\n",
      "Confusion matrix:\n",
      " [[24  1  0]\n",
      " [ 0 18  0]\n",
      " [ 0  0 16]]\n"
     ]
    }
   ],
   "source": [
    "# Tehtävän vastaukset. Huom! Älä muokkaa tätä solua, vaan aja se, kun olet suorittanut tehtävän. \n",
    "# Tallenna vastauksesi acc- ja cm-muuttujiin.\n",
    "print(f'Accuracy: {acc}')\n",
    "print(f'Confusion matrix:\\n {cm}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
